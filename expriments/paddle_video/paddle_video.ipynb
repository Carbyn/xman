{"cells":[{"metadata":{"collapsed":false,"id":"5F177446EDD74CF28000517FB8FC52D6"},"cell_type":"markdown","source":["## 整体思路\n","赛题要求利用BROAD视频精彩片段数据集预测视频中竞猜片段的位置。\n","整体解决方案有以下三步：\n","1. 多尺度滑窗的视频分类模型\n","2. 利用非极大值抑制对多尺度滑窗预测结果进行合并\n","3. 利用小尺度滑窗分类模型进行结果边界修正"],"outputs":[],"execution_count":null},{"metadata":{"collapsed":false,"id":"08B0D7F82B3E4009A18BBE41363F86CD"},"cell_type":"markdown","source":["### 多尺度滑窗的视频分类模型\n","#### 分类模型\n","复赛中提供了视频的音频和图像特征。本方案利用音频和图像特征对小段视频进行精彩/不精彩的二分类。\n","**视频特征:** 模型的输入特征为音频特征与图像特征拼接而成的4096维作为视频每帧的输入特征。\n","**分类网络:** 视频数据本身属于时序数据。经过选择，本方案选择5层栈式双向LSTM网络作为分类网络。\n","网络结构如图：\n","![image description](https://cdn.kesci.com/images/lab_upload/1521105403986_32600.png)\n","#### 滑窗尺寸\n","本方案选择一下几个尺寸滑窗，分别生成提取二分类模型\n","80,100,110,120,150,180,200,240,270\n","#### 预测\n","用上述不同尺寸的滑窗模型，对测试集视频进行滑动分类，得到所有滑窗的预测结果。\n",""],"outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"id":"94C048BCD47E4419ACF90889780AD07E"},"cell_type":"code","source":["### 网络模型\n","import cPickle\n","import sys\n","import json\n","import pandas as pd\n","import numpy as np\n","import gzip\n","import os\n","import random\n","import paddle.v2 as paddle\n","def lstm_net(input_dim,\n","                     class_dim=2,\n","                     hid_dim=512,\n","                     stacked_num=5,\n","                     is_infer=False):\n","    assert stacked_num % 2 == 1\n","\n","    fc_para_attr = paddle.attr.Param(learning_rate=1e-3)\n","    lstm_para_attr = paddle.attr.Param(initial_std=0., learning_rate=1.)\n","    para_attr = [fc_para_attr, lstm_para_attr]\n","    bias_attr = paddle.attr.Param(initial_std=0., l2_rate=0.)\n","    relu = paddle.activation.Relu()\n","    linear = paddle.activation.Linear()\n","\n","    data = paddle.layer.data(\"video\",\n","                             paddle.data_type.dense_vector_sequence(input_dim))\n","\n","    fc1 = paddle.layer.fc(input=data,\n","                          size=hid_dim,\n","                          act=linear,\n","                          bias_attr=bias_attr)\n","    lstm1 = paddle.layer.lstmemory(\n","        input=fc1, act=relu, bias_attr=bias_attr)\n","\n","    inputs = [fc1, lstm1]\n","    for i in range(2, stacked_num + 1):\n","        fc = paddle.layer.fc(input=inputs,\n","                             size=hid_dim,\n","                             act=linear,\n","                             param_attr=para_attr,\n","                             bias_attr=bias_attr)\n","        lstm = paddle.layer.lstmemory(\n","            input=fc,\n","            reverse=(i % 2) == 0,\n","            act=relu,\n","            bias_attr=bias_attr)\n","        inputs = [fc, lstm]\n","\n","    fc_last = paddle.layer.pooling(input=inputs[0], pooling_type=paddle.pooling.Max())\n","    lstm_last = paddle.layer.pooling(input=inputs[1], pooling_type=paddle.pooling.Max())\n","    output = paddle.layer.fc(input=[fc_last, lstm_last],\n","                             size=class_dim,\n","                             act=paddle.activation.Softmax(),\n","                             bias_attr=bias_attr,\n","                             param_attr=para_attr)\n","\n","    if not is_infer:\n","        lbl = paddle.layer.data(\"label\", paddle.data_type.integer_value(2))\n","        cost = paddle.layer.classification_cost(input=output, label=lbl)\n","        return cost, output, lbl\n","    else:\n","        return output"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"id":"3894841FD34D4F1E8B4E20CBEC38AA78"},"cell_type":"code","source":["# 数据reader\n","def load_json(file):\n","    with open(file) as json_file:\n","        data = json.load(json_file)\n","        return data\n","\n","    \n","#读取标签\n","def getLabelSet(data_type):\n","    data_dict = {}\n","    json_data = load_json(\"/mnt/BROAD-datasets/video/meta.json\")\n","    database = json_data['database']\n","    for video_name in database.keys():\n","        video_info = database[video_name]\n","        video_subset = video_info[\"subset\"]\n","        if video_subset == data_type:\n","            for index, item in enumerate(video_info['annotations']):\n","                video_info['annotations'][index] = item.values()[0]\n","            data_dict[video_name] = video_info['annotations']\n","    return data_dict\n","\n","\n","def getLabel(video, pos_st, pos_ed, data_dict):\n","    max_inter = 0\n","    for st, ed in data_dict[video]:\n","        intersection = max(0, min(ed, pos_ed) - max(st, pos_st))\n","        union = min(max(ed, pos_ed) - min(st, pos_st), ed - st + pos_ed - pos_st)\n","        overlap = float(intersection) / (union + 1e-8)\n","        max_inter = max(max_inter, intersection) \n","        if overlap > 0.8:\n","            return 1\n","    # 丢弃部分负样本，防止政府样本差距过大\n","    if int(random.random()*100) > 10:\n","        return -1 \n","    return 0\n","\n","def reader_creator(data_type, window_len=0, class_num=2):\n","    def multi_window_reader():\n","        json_data = load_json(\"/mnt/BROAD-datasets/video/meta.json\")\n","        database = json_data['database']\n","        data_dict = getLabelSet(data_type)\n","        cnt = 0\n","        for video in database.keys():\n","            dataSet = database[video][\"subset\"]\n","            if dataSet != data_type:\n","                continue\n","            #使用部分数据加速训练\n","            if int(random.random()*100) > 40:\n","                continue\n","            try:\n","                with open(\"/mnt/BROAD-datasets/video/\" + dataSet + \"/image_resnet50_feature/\" + str(video) + \".pkl\", 'rb') as f:\n","                    image_fea = np.array(cPickle.load(f))\n","                with open(\"/mnt/BROAD-datasets/video/\" + dataSet + \"/audio_feature/\" + str(video) + \".pkl\", 'rb') as f:\n","                    audio_fea = np.array(cPickle.load(f))\n","            except:\n","                continue\n","                \n","            print cnt,video\n","            cnt+=1\n","            #对齐音频图像序列\n","            image_len = np.shape(image_fea)[0]\n","            audio_len = np.shape(audio_fea)[0]\n","            if image_len < audio_len:\n","                audio_fea = audio_fea[:image_len]\n","            if audio_len < image_len:\n","                image_fea = image_fea[:audio_len]\n","            video_fea = np.append(image_fea , audio_fea, axis=1)\n","\n","            for wl in window_len:\n","                for pos in range(0, (np.shape(video_fea)[0] - wl), int(wl * 0.15)):\n","                    label = getLabel(video, pos, pos + wl, data_dict) \n","                    if label < 0:\n","                        continue                     \n","                    yield video_fea[pos:pos + wl], label \n","    return multi_window_reader"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"id":"AB09883027C043D6A34B6BCF9EDF000B"},"cell_type":"code","source":["#模型训练\n","def _train(now_wl, cost, prob, label):\n","    num_passes = 10\n","    window_len = [now_wl]\n","    model_path = \"/home/kesci/work/lstm_av_\" +str(window_len[0])+ \".tar.gz\"\n","\n","    if os.path.exists(model_path) :\n","        with gzip.open(model_path, 'r') as f:\n","            parameters = paddle.parameters.Parameters.from_tar(f)\n","    else:\n","        parameters = paddle.parameters.create(cost)\n","    adam_optimizer = paddle.optimizer.Adam(                                                                           \n","        learning_rate=1e-3,\n","        regularization=paddle.optimizer.L2Regularization(rate=1e-3),                                                  \n","        model_average=paddle.optimizer.ModelAverage(average_window=0.5))                                              \n","\n","    # create trainer\n","    trainer = paddle.trainer.SGD(\n","        cost=cost,                                                                                                    \n","        extra_layers=paddle.evaluator.auc(input=prob, label=label),                                                   \n","        parameters=parameters,                                                                                        \n","        update_equation=adam_optimizer)                                                                               \n","\n","    # begin training network                                                                                          \n","    feeding = {\"video\": 0, \"label\": 1}                                                                                 \n","    def _event_handler(event):\n","        \"\"\"\n","        Define end batch and end pass event handler                                                                   \n","        \"\"\"\n","        if isinstance(event, paddle.event.EndIteration):                                                              \n","            if event.batch_id % 10 == 0: \n","                print \"Pass %d, Batch %d, Cost %f, %s\\n\" % (                                                    \n","                    event.pass_id, event.batch_id, event.cost, event.metrics)\n","\n","        if isinstance(event, paddle.event.EndPass): \n","            print 'model save'\n","            with gzip.open(model_path, \"w\") as f:                                                           \n","                parameters.to_tar(f)  \n","            print 'start test'\n","            result = trainer.test(reader=paddle.batch(reader_creator('validation',window_len,class_num=2),256), feeding=feeding)                                            \n","            print \"Test at Pass %d, %s \\n\" % (event.pass_id,                                                \n","                                                        result.metrics)                                              \n","                                                                    \n","\n","    trainer.train(\n","        reader=paddle.batch(paddle.reader.shuffle(reader_creator('training',window_len,class_num=2),1280),256),\n","        event_handler=_event_handler,\n","        feeding=feeding,\n","        num_passes=num_passes)\n","def train():\n","    dict_dim = 4096\n","    paddle.init(use_gpu=True, trainer_count=1)\n","    # network config                                                                                                  \n","    cost, prob, label =lstm_net(dict_dim)\n","    # 多尺度滑窗\n","    window_lens = [80,100,120,130,150,160,180,210,240,270]\n","    for wl in window_lens:\n","        _train(wl,cost,prob,label)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"id":"00B55792C9584CB69A5132EEAFA51DA3"},"cell_type":"code","source":["#预测\n","def infer():\n","    prob_layer = lstm_net(4096,is_infer=True)\n","    paddle.init(use_gpu=True, trainer_count=1)\n","    def _infer(data_type, window_len, proposal_data, window_stride):\n","        print window_len\n","        json_data = load_json(\"/mnt/BROAD-datasets/video/meta.json\")\n","        database = json_data['database']\n","        window_lens = [window_len]\n","        model_path = \"/home/kesci/work/lstm_av_\" + str(window_len) +\".tar.gz\"\n","        # load the trained models\n","        if os.path.exists(model_path):\n","            with gzip.open(model_path, 'r') as f:\n","                parameters = paddle.parameters.Parameters.from_tar(f)\n","        index = 0\n","        for video in database.keys():\n","            dataSet = database[video][\"subset\"]\n","            if dataSet != data_type:\n","                continue\n","            try:\n","                with open(\"/mnt/BROAD-datasets/video/\" + dataSet + \"/image_resnet50_feature/\" + str(video) + \".pkl\", 'rb') as f:\n","                    image_fea = np.array(cPickle.load(f))\n","                with open(\"/mnt/BROAD-datasets/video/\" + dataSet + \"/audio_feature/\" + str(video) + \".pkl\", 'rb') as f:\n","                    audio_fea = np.array(cPickle.load(f))\n","\n","            except:\n","                continue\n","            print index,video\n","            try:\n","                audio_fea = audio_fea[:np.shape(image_fea)[0]]\n","                image_fea = image_fea[:np.shape(audio_fea)[0]]\n","                video_fea = np.append(image_fea, audio_fea, axis=1)\n","            except:\n","                continue\n","            index += 1\n","            video_len = np.shape(video_fea)[0]\n","            this_vid_proposals = []\n","            inputs = []\n","            for pos in range(0, video_len - window_lens[0], window_stride):\n","                inputs.append([video_fea[pos:pos + window_lens[0]]])\n","            probs = paddle.infer(\n","                output_layer=prob_layer, parameters=parameters, input=inputs, field=\"value\")\n","            for stride_index, prob in enumerate(probs):\n","                pos = stride_index * window_stride\n","                score = int(prob[1] * 100) / 100.0\n","                if score == 0.0:\n","                    continue\n","                proposal = {\n","                        'score': int(prob[1] * 100) / 100.0,\n","                        'segment': [pos, pos + window_lens[0]],\n","                        }\n","                this_vid_proposals += [proposal]\n","            if  not proposal_data['results'].has_key(video): \n","                proposal_data['results'][video] = this_vid_proposals\n","            else :\n","                proposal_data['results'][video] += this_vid_proposals\n","\n","    data_type = 'testing'\n","    window_lens = [80,100,120,130,150,160,180,210,240,270]\n","    window_strides = [9,12,16,16,16,16,16,16,16,16,16]\n","    proposal_data = {'results': {}, 'version': \"VERSION 1.0\"}\n","    for index, window_len in enumerate(window_lens):\n","        _infer(data_type, window_len, proposal_data, window_strides[index])\n","        with open(\"/home/kesci/work/res/\" + data_type + \".json\", 'w') as fobj:\n","            json.dump(proposal_data, fobj)\n",""],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"id":"7C5EBBB58B264B628373E9638ED244BF"},"cell_type":"code","source":["#首先进行train()\n","train()\n","#train之后重启kernel 进行infer\n","infer()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"5D992715CC5C49D39D16EA9D6CBFB64D"},"cell_type":"markdown","source":["### 利用非极大值抑制对多尺度滑窗预测结果进行合并\n","利用非极大值抑制算法，对多尺度滑窗的预测结果进行处理，得到最终的预测结果。\n","此时的结果在测试集以及预测集上，可以达到31分左右。"],"outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"id":"26B2D0AB9342473A805A7C8FE54625B3"},"cell_type":"code","source":["### nms合并结果\n","def nms_detections(props, scores, overlap=0.7):\n","    props = np.array(props)\n","    scores = np.array(scores)\n","    t1 = props[:, 0]\n","    t2 = props[:, 1]\n","    ind = np.argsort(scores)\n","    area = (t2 - t1 + 1).astype(float)\n","    pick = []\n","    while len(ind) > 0:\n","        i = ind[-1]\n","        pick.append(i)\n","        ind = ind[:-1]\n","        tt1 = np.maximum(t1[i], t1[ind])\n","        tt2 = np.minimum(t2[i], t2[ind])\n","        wh = np.maximum(0., tt2 - tt1 + 1.0)\n","        o = wh / (area[i] + area[ind] - wh)\n","        ind = ind[np.nonzero(o <= overlap)[0]]\n","    nms_props, nms_scores = props[pick, :], scores[pick]\n","    return nms_props, nms_scores\n","\n","def refine(data_type):\n","    proposal_data = {'results': {}, 'version': \"VERSION 1.0\"}\n","    json_data = load_json(\"res/\" + data_type + \".json\")\n","    database = json_data['results']\n","    for video in database.keys():\n","        this_vid_proposals = []\n","        probs = []\n","        scores = []\n","        for index, i in enumerate(database[video]):\n","            st, ed = i['segment']\n","            score = i['score']\n","            probs.append([st, ed])\n","            scores.append(i['score'])\n","        if len(probs) == 0:\n","            continue\n","        nms_props,nms_scores = nms_detections(probs, scores, 0.05)\n","        for prob, score in zip(nms_props, nms_scores):\n","            proposal = {\n","                    'score': score,\n","                    'segment': [prob[0], prob[1]],\n","                   }\n","            this_vid_proposals += [proposal]\n","        proposal_data['results'][video] = this_vid_proposals\n","    with open(\"res/\" + data_type + \"_refine.json\", 'w') as fobj:\n","        json.dump(proposal_data, fobj)\n","#利用infer的结果进行合并\n","refine('testing')"],"execution_count":null,"outputs":[]},{"metadata":{"id":"2DE414B04CA445709D5369C327360422"},"cell_type":"markdown","source":["### 利用小尺度滑窗分类模型进行结果边界修正\n","利用小尺寸滑窗例如8,12,16等进行二分类，通过小滑窗的预测模型，上步得到的结果进行边界修正。\n","具体修正策略详见代码。具体步骤如下\n","1. 利用小尺度滑窗训练二分类模型 \n","2. 利用小尺度滑窗二分类模型预测视频每个小段得分\n","3. 利用得到小尺度预测结果和上步中得到的预测结果，根据两者的重合度，修正边界\n","\n","在本次比赛中，由于时间的限制，只使用16长的小滑窗，经过小尺度分类模型边界修正，在验证集和测试集上可以达到36分。\n","使用不同尺度的滑窗，可能得到更优化的结果。"],"outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"id":"50B2E6FEDE934E479B099147F90078C5"},"cell_type":"code","source":["# 小尺度滑窗分类reader\n","def mini_getLabel(video, pos_st, pos_ed, data_dict):\n","    max_inter = 0\n","    for st, ed in data_dict[video]:\n","        intersection = max(0, min(ed, pos_ed) - max(st, pos_st))\n","        union = min(max(ed, pos_ed) - min(st, pos_st), ed - st + pos_ed - pos_st)\n","        overlap = float(intersection) / (pos_ed - pos_st)\n","        if overlap > 0.9:\n","            return 1\n","    return 0\n","\n","def mini_reader_creator(data_type, window_len=0, class_num=2):\n","    def multi_window_reader():\n","        json_data = load_json(\"/mnt/BROAD-datasets/video/meta.json\")\n","        database = json_data['database']\n","        data_dict = getLabelSet(data_type)\n","        cnt = 0\n","        for video in database.keys():\n","            dataSet = database[video][\"subset\"]\n","            if dataSet != data_type:\n","                continue\n","            if int(random.random()*100) > 100:\n","                continue\n","            try:\n","                with open(\"/mnt/BROAD-datasets/video/\" + dataSet + \"/image_resnet50_feature/\" + str(video) + \".pkl\", 'rb') as f:\n","                    image_fea = np.array(cPickle.load(f))\n","                with open(\"/mnt/BROAD-datasets/video/\" + dataSet + \"/audio_feature/\" + str(video) + \".pkl\", 'rb') as f:\n","                    audio_fea = np.array(cPickle.load(f))\n","            except:\n","                continue\n","            cnt+=1\n","            image_len = np.shape(image_fea)[0]\n","            audio_len = np.shape(audio_fea)[0]\n","            if image_len < audio_len:\n","                audio_fea = audio_fea[:image_len]\n","            if audio_len < image_len:\n","                image_fea = image_fea[:audio_len]\n","            video_fea = np.append(image_fea , audio_fea, axis=1)\n","            pos_cnt = 0\n","            neg_cnt = 0\n","            for wl in window_len:\n","                for pos in range(0, (np.shape(video_fea)[0] - wl), wl):\n","                    label = mini_getLabel(video, pos, pos + wl, data_dict)                        \n","                    yield video_fea[pos:pos + wl], label \n","    return multi_window_reader"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"id":"336C0E3C5982438E8ECD7968D1FF5804"},"cell_type":"code","source":["#小尺度滑窗训练\n","def _mini_train(now_wl, cost, prob, label):\n","    num_passes = 6\n","    window_len = [now_wl]\n","    model_path = \"/home/kesci/work/lstm_av_\" +str(window_len[0])+ \".tar.gz\"\n","\n","    if os.path.exists(model_path) :\n","        with gzip.open(model_path, 'r') as f:\n","            parameters = paddle.parameters.Parameters.from_tar(f)\n","    else:\n","        parameters = paddle.parameters.create(cost)\n","    adam_optimizer = paddle.optimizer.Adam(                                                                           \n","        learning_rate=1e-3,\n","        regularization=paddle.optimizer.L2Regularization(rate=1e-3),                                                  \n","        model_average=paddle.optimizer.ModelAverage(average_window=0.5))                                              \n","\n","    # create trainer\n","    trainer = paddle.trainer.SGD(\n","        cost=cost,                                                                                                    \n","        extra_layers=paddle.evaluator.auc(input=prob, label=label),                                                   \n","        parameters=parameters,                                                                                        \n","        update_equation=adam_optimizer)                                                                               \n","\n","    # begin training network                                                                                          \n","    feeding = {\"video\": 0, \"label\": 1}                                                                                 \n","    def _event_handler(event):\n","        \"\"\"\n","        Define end batch and end pass event handler                                                                   \n","        \"\"\"\n","        if isinstance(event, paddle.event.EndIteration):                                                              \n","            if event.batch_id % 10 == 0: \n","                print \"Pass %d, Batch %d, Cost %f, %s\\n\" % (                                                    \n","                    event.pass_id, event.batch_id, event.cost, event.metrics)\n","\n","        if isinstance(event, paddle.event.EndPass): \n","            print 'model save'\n","            with gzip.open(model_path, \"w\") as f:                                                           \n","                parameters.to_tar(f)  \n","            print 'start test'\n","            result = trainer.test(reader=paddle.batch(mini_reader_creator('validation',window_len,class_num=2),256), feeding=feeding)                                            \n","            print \"Test at Pass %d, %s \\n\" % (event.pass_id,                                                \n","                                                        result.metrics)                                              \n","                                                                    \n","\n","    trainer.train(\n","        reader=paddle.batch(paddle.reader.shuffle(mini_reader_creator('training',window_len,class_num=2),1280),256),\n","        event_handler=_event_handler,\n","        feeding=feeding,\n","        num_passes=num_passes)\n","def mini_train():\n","    dict_dim = 4096\n","    paddle.init(use_gpu=True, trainer_count=1)\n","    # network config                                                                                                  \n","    cost, prob, label =lstm_net(dict_dim)\n","    window_lens = [16]\n","    for wl in window_lens:\n","        _mini_train(wl,cost,prob,label)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"id":"70A76E01B04F449E8A7D01C91D776747"},"cell_type":"code","source":["#小尺度滑窗预测\n","def mini_infer():\n","    prob_layer = lstm_net(4096,is_infer=True)\n","    paddle.init(use_gpu=True, trainer_count=1)\n","    def _infer(data_type, window_len, proposal_data, window_stride):\n","        print window_len\n","        json_data = load_json(\"/mnt/BROAD-datasets/video/meta.json\")\n","        database = json_data['database']\n","        window_lens = [window_len]\n","        model_path = \"/home/kesci/work/lstm_av_\" + str(window_len) +\".tar.gz\"\n","        # load the trained models\n","        if os.path.exists(model_path):\n","            with gzip.open(model_path, 'r') as f:\n","                parameters = paddle.parameters.Parameters.from_tar(f)\n","        index = 0\n","        for video in database.keys():\n","            dataSet = database[video][\"subset\"]\n","            if dataSet != data_type:\n","                continue\n","            try:\n","                with open(\"/mnt/BROAD-datasets/video/\" + dataSet + \"/image_resnet50_feature/\" + str(video) + \".pkl\", 'rb') as f:\n","                    image_fea = np.array(cPickle.load(f))\n","                with open(\"/mnt/BROAD-datasets/video/\" + dataSet + \"/audio_feature/\" + str(video) + \".pkl\", 'rb') as f:\n","                    audio_fea = np.array(cPickle.load(f))\n","\n","            except:\n","                continue\n","            print index,video\n","            try:\n","                audio_fea = audio_fea[:np.shape(image_fea)[0]]\n","                image_fea = image_fea[:np.shape(audio_fea)[0]]\n","                video_fea = np.append(image_fea, audio_fea, axis=1)\n","            except:\n","                print np.shape(audio_fea)\n","                print np.shape(image_fea)\n","                continue\n","            index += 1\n","            video_len = np.shape(video_fea)[0]\n","            this_vid_proposals = []\n","            inputs = []\n","            for pos in range(0, video_len - window_lens[0], window_stride):\n","                inputs.append([video_fea[pos:pos + window_lens[0]]])\n","            probs = paddle.infer(\n","                output_layer=prob_layer, parameters=parameters, input=inputs, field=\"value\")\n","            for stride_index, prob in enumerate(probs):\n","                pos = stride_index * window_stride\n","                score = int(prob[1] * 100) / 100.0\n","                if score == 0.0:\n","                    continue\n","                proposal = {\n","                        'score': int(prob[1] * 100) / 100.0,\n","                        'segment': [pos, pos + window_lens[0]],\n","                        }\n","                this_vid_proposals += [proposal]\n","            if  not proposal_data['results'].has_key(video): \n","                proposal_data['results'][video] = this_vid_proposals\n","            else :\n","                proposal_data['results'][video] += this_vid_proposals\n","\n","    data_type = 'testing'\n","    window_lens = [16]\n","    window_strides = [16]\n","    proposal_data = {'results': {}, 'version': \"VERSION 1.0\"}\n","    for index, window_len in enumerate(window_lens):\n","        _infer(data_type, window_len, proposal_data, window_strides[index])\n","        with open(\"/home/kesci/work/res/\" + data_type + \"_mini.json\", 'w') as fobj:\n","            json.dump(proposal_data, fobj)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"id":"0EFA44B2BDE344EA83E3E9F6432D448F"},"cell_type":"code","source":["def mini_refine(data_type):\n","    proposal_data = {'results': {}, 'version': \"VERSION 1.0\"}\n","    json_data = load_json(\"/home/kesci/work/res/\" + data_type + \"_refine.json\")\n","    av = json_data['results']\n","    json_data = load_json(\"/home/kesci/work/res/\" + data_type + \"_mini.json\")\n","    mini = json_data['results']\n","    def getOverlap(segment) :\n","        pos_st,pos_ed = segment\n","        in_len = 0\n","        last_st = 99999\n","        last_ed = 0\n","        for i in mini[video]:\n","            st, ed = i['segment']\n","            if ed < pos_st or st > pos_ed:continue\n","            intersection = max(0, min(ed, pos_ed) - max(st, pos_st))\n","            union = min(max(ed, pos_ed) - min(st, pos_st), ed - st + pos_ed - pos_st)\n","            overlap = float(intersection) / (pos_ed - pos_st)\n","            if overlap > 0 and i['score']>0.0:\n","                in_len+=16.0\n","                last_st = min(last_st, st)\n","                last_ed = max(last_ed, ed)\n","        return in_len/(pos_ed-pos_st), last_st, last_ed \n","    for video in av.keys():\n","        this_vid_proposals = []\n","        for index, i in enumerate(av[video]):\n","            score = i['score']\n","            segment = i['segment']\n","            st,ed = segment\n","            overlap,last_st,last_ed = getOverlap(segment)\n","            if (overlap>0.2):\n","                st = last_st\n","                ed = last_ed\n","            else :\n","                continue\n","            proposal = {\n","                    'score': score,\n","                    'segment': [st, ed],\n","                   }\n","            this_vid_proposals += [proposal]\n","        proposal_data['results'][video] = this_vid_proposals\n","    with open(\"/home/kesci/work/res/\" + data_type + \"_mini_refine.json\", 'w') as fobj:\n","        json.dump(proposal_data, fobj)"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"id":"3D0B42F5A0BB47108D7836FF9155010E"},"cell_type":"code","source":["#首先进行小尺度窗口模型训练\n","mini_train()\n","#训练完成后进行小尺度窗口预测\n","mini_infer()\n","#得到小尺度窗口预测结果后与上步结果进行合并\n","mini_refine()"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python2","display_name":"Python 2","language":"python"},"language_info":{"mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"name":"python","nbconvert_exporter":"python","version":"2.7.9"}},"nbformat":4,"nbformat_minor":0}